{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e3e7ce8-143a-4c4e-9e23-53dff76ec176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../code\")\n",
    "\n",
    "from make_droso_figures import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e11e95e7-7527-4796-b5b4-eacf01930bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy \n",
    "from scipy import ndimage\n",
    "\n",
    "def get_vals(cool, l1, l2):\n",
    "    vals = np.asarray(cool.matrix(balance=False).fetch(l1, l2))\n",
    "    vals[np.isnan(vals)] = 0\n",
    "    v = vals.sum()\n",
    "    return v\n",
    "\n",
    "\n",
    "def call(loops_bedtool):\n",
    "    values, shifted_values, not_shifted, is_shifted, places, shifted_places = {}, {}, [], [], [], []\n",
    "    for cool_name in cools:\n",
    "        values[cool_name] = []\n",
    "        shifted_values[cool_name] = []\n",
    "    l1, l2 = loops_bedtool[:3], loops_bedtool[3:6]\n",
    "    newl1 = (l1[0], int(l1[1])-res*wsz, int(l1[2])+res*(wsz))\n",
    "    newl2 = (l2[0], int(l2[1])-res*wsz, int(l2[2])+res*(wsz))\n",
    "    c = 0\n",
    "    for cool_name in cools:\n",
    "        cool = cools[cool_name]\n",
    "        try:\n",
    "            val = get_vals(cool, newl1, newl2)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return None\n",
    "            continue\n",
    "        values[cool_name].append(val)\n",
    "        if c == 0: # First run around\n",
    "            place = \"_\".join([str(x) for x in newl1]) + \"_\" + \"_\".join([str(x) for x in newl2])\n",
    "            places.append(place)\n",
    "            not_shifted.append(0)\n",
    "        for shift in range(50, 150, 10):\n",
    "            try:\n",
    "                shifted_l1 = (l1[0], int(l1[1])-shift*res-res*wsz, int(l1[2])-shift*res+res*(wsz))\n",
    "                shifted_l2 = (l2[0], int(l2[1])-shift*res-res*wsz, int(l2[2])-shift*res+res*(wsz))\n",
    "                shifted_val = get_vals(cool, shifted_l1, shifted_l2)\n",
    "            except:\n",
    "                shifted_l1 = (l1[0], int(l1[1])+shift*res-res*wsz, int(l1[2])+shift*res+res*(wsz))\n",
    "                shifted_l2 = (l2[0], int(l2[1])+shift*res-res*wsz, int(l2[2])+shift*res+res*(wsz))\n",
    "                shifted_val = get_vals(cool, shifted_l1, shifted_l2)\n",
    "            shifted_values[cool_name].append(shifted_val)\n",
    "            if c == 0: # First run around\n",
    "                shifted_place = \"_\".join([str(x) for x in shifted_l1]) + \"_\" + \"_\".join([str(x) for x in shifted_l2])\n",
    "                shifted_places.append(shifted_place)\n",
    "                is_shifted.append(1)\n",
    "        c += 1\n",
    "    # print(\"PLACES ARE\", places)\n",
    "    return values, shifted_values, not_shifted, is_shifted, places, shifted_places \n",
    "\n",
    "def rownorm(df):\n",
    "    df = (df.T/df.mean(axis=1)).T\n",
    "    return df\n",
    "\n",
    "def colnorm(df):\n",
    "    df = (df/df.mean(axis=0))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31313015-1dd4-4655-abd2-05979ac7f72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cool_pref = '../../cools/'\n",
    "exp_pref = '../../obs_exp/expected/replicates'\n",
    "pbt_file = '../loops/loose/full_loops.loops' \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceceac4-f86e-4d9d-8c5b-49181321dd41",
   "metadata": {},
   "source": [
    "### NC1-8, NC14, S10-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d174d3d-a53a-4e8b-96aa-2520604c5897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cooler \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pybedtools as pbt\n",
    "\n",
    "values = {}\n",
    "shifted_values = {}\n",
    "places = []\n",
    "shifted_places = []\n",
    "\n",
    "\n",
    "not_shifted = []\n",
    "is_shifted = []\n",
    "\n",
    "cools = {}\n",
    "\n",
    "\n",
    "files = [\n",
    "        'nc1-8_1_2.base_resolution=100.mcool',\n",
    "        'nc1-8_2_1.base_resolution=100.mcool',\n",
    "        'nc1-8_2_2.base_resolution=100.mcool',\n",
    "        'nc1-8_1_1.base_resolution=100.mcool',\n",
    "        's10-12_1_1.base_resolution=100.mcool',\n",
    "        's10-12_1_2.base_resolution=100.mcool',\n",
    "        's10-12_2_1.base_resolution=100.mcool',\n",
    "        's10-12_2_2.base_resolution=100.mcool',\n",
    "        'nc14_1_1.base_resolution=100.mcool',\n",
    "        'nc14_1_2.base_resolution=100.mcool',\n",
    "        'nc14_2_1.base_resolution=100.mcool',\n",
    "        'nc14_2_2.base_resolution=100.mcool',\n",
    "        'nc14_FED_1_1.base_resolution=100.mcool',\n",
    "        'nc14_FED_1_2.base_resolution=100.mcool',\n",
    "        'nc14_FED_rerun_1_1.base_resolution=100.mcool',\n",
    "        'nc14_FED_rerun_1_2.base_resolution=100.mcool',\n",
    "        'nc12_mitotic_FED_1_1.base_resolution=100.mcool',\n",
    "        'nc12_mitotic_FED_1_2.base_resolution=100.mcool' ,   \n",
    "        'nc12_mitotic_FED_rerun_1_1.base_resolution=100.mcool',\n",
    "        'nc12_mitotic_FED_rerun_1_2.base_resolution=100.mcool',\n",
    "        'nc14_FED_1_1.base_resolution=100.mcool',\n",
    "        'nc14_FED_1_2.base_resolution=100.mcool',\n",
    "]\n",
    "\n",
    "import pandas as pd\n",
    "res = 800\n",
    "\n",
    "balanced_expected = {}\n",
    "count_expected = {}\n",
    "for file in files:\n",
    "    replicate = file.split(\".\")[0]\n",
    "    full_path = cool_pref + file + f\"::/resolutions/{res}\"\n",
    "    cools[replicate] = cooler.Cooler(full_path)\n",
    "    expected_df = pd.read_csv(f'{exp_pref}/expected_{file}_{res}.tsv', sep='\\t')\n",
    "    count_expected[replicate] = {} \n",
    "    balanced_expected[replicate] = {} \n",
    "\n",
    "    for chrom in cools[replicate].chromsizes.index:\n",
    "        sub_df = expected_df[expected_df.region == chrom]\n",
    "        sub_df = sub_df.sort_values('diag')\n",
    "        diags = sub_df.diag\n",
    "        balanced_values = sub_df['balanced.avg']\n",
    "        count_values = sub_df['count.avg']\n",
    "        balanced_expected[replicate][chrom] = dict(zip(diags, balanced_values))\n",
    "        count_expected[replicate][chrom] = dict(zip(diags, count_values))\n",
    "    print(\"Done with\", file)\n",
    "print(\"Past Sorting\")\n",
    "for cool_name in cools:\n",
    "    values[cool_name] = []\n",
    "    shifted_values[cool_name] = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "329c5ae3-ab1a-43af-9136-739e985e741d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce40cfd3-e2e6-419d-b187-586379803ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bedtool file: ./loops/loose/full_loops.loops\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "n_workers = 30\n",
    "\n",
    "wsz = 0\n",
    "res = 800\n",
    "\n",
    "print(f\"Using bedtool file: {pbt_file}\")\n",
    "peaks_loops = list(pbt.BedTool(pbt_file))\n",
    "with ProcessPoolExecutor(max_workers=n_workers) as e:\n",
    "    loop_parts = e.map(call, peaks_loops, chunksize=1)\n",
    "\n",
    "reses = []\n",
    "for part in loop_parts:\n",
    "    reses.append(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3f50428-13b4-4365-b5bd-67daddba2d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_values, all_shifted_values, all_not_shifted, all_is_shifted, all_places, all_shifted_places = {}, {}, [], [] ,[] ,[]\n",
    "for cool_name in cools:\n",
    "    all_values[cool_name] = []\n",
    "    all_shifted_values[cool_name] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2247a76-1727-4970-8bea-9b376e078d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "for part in reses:\n",
    "    if part is None:\n",
    "        continue\n",
    "    else:\n",
    "        values, shifted_values, not_shifted, is_shifted, places, shifted_places = part\n",
    "    for cool_name in cools:\n",
    "        all_values[cool_name] += list(values[cool_name])\n",
    "        all_shifted_values[cool_name] += list(shifted_values[cool_name])\n",
    "    all_not_shifted += not_shifted\n",
    "    all_is_shifted += is_shifted\n",
    "    all_places += places\n",
    "    all_shifted_places += shifted_places\n",
    "    c+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33749863-2ddd-4b88-bc4f-8d5e16b82bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1029\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "hic_reads = pd.DataFrame()\n",
    "for cool_name in cools:\n",
    "    hic_reads[cool_name] = (all_values[cool_name] + all_shifted_values[cool_name])\n",
    "\n",
    "hic_reads[\"shifted\"] = all_not_shifted + all_is_shifted\n",
    "hic_reads['places'] = all_places + all_shifted_places\n",
    "\n",
    "print(len(all_not_shifted))\n",
    "final_places = hic_reads['places'].values\n",
    "diags = []\n",
    "chroms = []\n",
    "for place in final_places:\n",
    "    spl = place.split(\"_\")\n",
    "    chrom = spl[0]\n",
    "    start = int(spl[1])\n",
    "    end = int(spl[4])\n",
    "    diag = (end-start)//res\n",
    "    diags.append(diag)\n",
    "    chroms.append(chrom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "893288bc-afc6-4d11-bc9c-818d59732902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with nc1-8_1_2\n",
      "Done with nc1-8_2_1\n",
      "Done with nc1-8_2_2\n",
      "Done with nc1-8_1_1\n",
      "Done with s10-12_1_1\n",
      "Done with s10-12_1_2\n",
      "Done with s10-12_2_1\n",
      "Done with s10-12_2_2\n",
      "Done with nc14_1_1\n",
      "Done with nc14_1_2\n",
      "Done with nc14_2_1\n",
      "Done with nc14_2_2\n",
      "Done with nc14_FED_1_1\n",
      "Done with nc14_FED_1_2\n",
      "Done with nc14_FED_rerun_1_1\n",
      "Done with nc14_FED_rerun_1_2\n",
      "Done with nc12_mitotic_FED_1_1\n",
      "Done with nc12_mitotic_FED_1_2\n",
      "Done with nc12_mitotic_FED_rerun_1_1\n",
      "Done with nc12_mitotic_FED_rerun_1_2\n"
     ]
    }
   ],
   "source": [
    "raw_expected_df = pd.DataFrame()\n",
    "balanced_expected_df = pd.DataFrame()\n",
    "\n",
    "for cool_name in count_expected:\n",
    "    raw_values = []\n",
    "    balanced_values = []    \n",
    "    for i in range(len(diags)):\n",
    "        chrom = chroms[i]\n",
    "        diag = diags[i]\n",
    "    \n",
    "        raw_diag_dict = count_expected[cool_name][chrom]\n",
    "        raw_exp = np.nanmean([raw_diag_dict[x] for x in np.arange(diag-1-wsz, diag+1+wsz+1)])        \n",
    "\n",
    "        bal_diag_dict = balanced_expected[cool_name][chrom]\n",
    "        bal_exp = np.nanmean([bal_diag_dict[x] for x in np.arange(diag-1-wsz, diag+1+wsz+1)])                \n",
    "        \n",
    "        raw_values.append(raw_exp)\n",
    "        balanced_values.append(bal_exp)\n",
    "\n",
    "    assert len(diags) == len(final_places)\n",
    "\n",
    "    raw_expected_df[cool_name] = raw_values\n",
    "    balanced_expected_df[cool_name] = balanced_values\n",
    "    print('Done with', cool_name)\n",
    "raw_expected_df['diag'] = arr(diags)\n",
    "balanced_expected_df['diag'] = arr(diags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "845f13d0-e90a-4271-b3f6-1ad54794152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_expected_df.columns = [x.replace(\"14_FED\", \"14.FED\") for x in raw_expected_df.columns]\n",
    "raw_expected_df.columns = [x.replace(\"14_for\", \"14.for\") for x in raw_expected_df.columns]\n",
    "raw_expected_df.columns = [x.replace(\"FED_rerun\", \"FED.rerun\") for x in raw_expected_df.columns]\n",
    "raw_expected_df.columns = [x.replace(\"12_mitotic_FED\", \"12.mitotic.FED\") for x in raw_expected_df.columns]\n",
    "raw_expected_df.columns = [x.replace(\"12_mitotic_for\", \"12.mitotic.for\") for x in raw_expected_df.columns]\n",
    "\n",
    "hic_reads.columns = [x.replace(\"14_FED\", \"14.FED\") for x in hic_reads.columns]\n",
    "hic_reads.columns = [x.replace(\"14_for\", \"14.for\") for x in hic_reads.columns]\n",
    "hic_reads.columns = [x.replace(\"FED_rerun\", \"FED.rerun\") for x in hic_reads.columns]\n",
    "hic_reads.columns = [x.replace(\"12_mitotic_FED\", \"12.mitotic.FED\") for x in hic_reads.columns]\n",
    "hic_reads.columns = [x.replace(\"12_mitotic_for\", \"12.mitotic.for\") for x in hic_reads.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75077b21-0f6c-44a1-8748-802cc7169157",
   "metadata": {},
   "outputs": [],
   "source": [
    "hic_reads = hic_reads.iloc[:, ~hic_reads.columns.str.contains(\"form\")]\n",
    "raw_expected_df = raw_expected_df.iloc[:, ~raw_expected_df.columns.str.contains(\"form\")]\n",
    "\n",
    "# (hic_reads).drop(hic_reads.columns[hic_reads.columns.str.contains(\"FED\")], axis=1).to_csv('LOOSE_hic_values_close.csv', index=None,)\n",
    "(hic_reads).to_csv('../DESEQ2/LOOSE_hic_values_close.csv', index=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3a4292-134a-4d54-99bc-cc329fdb9724",
   "metadata": {},
   "source": [
    "#### Make normalization df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5a404bd-cf10-4e5c-a294-41b737bde57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hic_reads = hic_reads.iloc[:, ~hic_reads.columns.str.contains(\"form\")]\n",
    "raw_expected_df = raw_expected_df.iloc[:, ~raw_expected_df.columns.str.contains(\"form\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ab7e4239-5d03-4db1-be42-18fc282cf608",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_exps = raw_expected_df.drop(['diag'], axis=1)#.drop(hic_reads.columns[hic_reads.columns.str.contains(\"FED\")], axis=1)\n",
    "rownorm(1/raw_exps).to_csv('../DESEQ2/LOOSE_raw_normalization_df.csv', index=None)\n",
    "\n",
    "# rownorm(1/bal_exps).to_csv('REPLICATE_DESEQ/LOOSE_balanced_normalization_df.csv', index=None)\n",
    "# rownorm(balancing_df/bal_exps).drop(['diag'], axis=1).to_csv('REPLICATE_DESEQ/LOOSE_rebalanced_balanced_normalization_df.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2c30ed32-3e64-4ed5-823b-e56dcc9332b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rownorm(df):\n",
    "    df = (df.T/df.mean(axis=1)).T\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
